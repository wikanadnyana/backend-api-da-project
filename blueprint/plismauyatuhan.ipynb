{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  round  venue   gf   ga   xg  xga  poss  formation    sh  ...  \\\n",
      "0           0     33      0  0.0  0.0  1.4  0.8  49.0          4  11.0  ...   \n",
      "1           1     35      1  2.0  0.0  2.4  0.4  64.0          4  25.0  ...   \n",
      "2           2     37      0  5.0  2.0  3.5  1.0  67.0          4  30.0  ...   \n",
      "3           3      2      0  1.0  3.0  0.3  1.8  43.0          4   6.0  ...   \n",
      "4           4      3      1  2.0  0.0  2.1  0.7  43.0          4  14.0  ...   \n",
      "\n",
      "   ga_rolling  sh_rolling  sot_rolling  dist_rolling  fk_rolling  pk_rolling  \\\n",
      "0    2.333333   17.333333     6.333333     17.300000    0.333333         0.0   \n",
      "1    1.333333   12.000000     3.666667     16.566667    0.333333         0.0   \n",
      "2    0.000000   17.666667     6.333333     17.166667    1.000000         0.0   \n",
      "3    0.666667   22.000000     8.000000     17.500000    1.333333         0.0   \n",
      "4    1.666667   20.333333     8.333333     18.500000    1.666667         0.0   \n",
      "\n",
      "   pkatt_rolling  home_code  target_away  target_home  \n",
      "0            0.0          0            0            0  \n",
      "1            0.0          0            0            1  \n",
      "2            0.0          0            0            1  \n",
      "3            0.0          0            1            0  \n",
      "4            0.0          0            0            1  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "(1806, 30)\n"
     ]
    }
   ],
   "source": [
    "dataTrain=pd.read_csv(\"../data/newtrain.csv\")\n",
    "dataTest=pd.read_csv(\"../data/newtest.csv\")\n",
    "print(dataTrain.head())\n",
    "print(dataTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataTrain[\"Unnamed: 0\"]\n",
    "del dataTest[\"Unnamed: 0\"]\n",
    "del dataTrain[\"target_away\"]\n",
    "del dataTest[\"target_away\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1806 entries, 0 to 1805\n",
      "Data columns (total 28 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   round          1806 non-null   int64  \n",
      " 1   venue          1806 non-null   int64  \n",
      " 2   gf             1806 non-null   float64\n",
      " 3   ga             1806 non-null   float64\n",
      " 4   xg             1806 non-null   float64\n",
      " 5   xga            1806 non-null   float64\n",
      " 6   poss           1806 non-null   float64\n",
      " 7   formation      1806 non-null   int64  \n",
      " 8   sh             1806 non-null   float64\n",
      " 9   sot            1806 non-null   float64\n",
      " 10  dist           1806 non-null   float64\n",
      " 11  fk             1806 non-null   float64\n",
      " 12  pk             1806 non-null   float64\n",
      " 13  pkatt          1806 non-null   float64\n",
      " 14  venue_code     1806 non-null   int64  \n",
      " 15  opp_code       1806 non-null   int64  \n",
      " 16  hour           1806 non-null   int64  \n",
      " 17  day_code       1806 non-null   int64  \n",
      " 18  gf_rolling     1806 non-null   float64\n",
      " 19  ga_rolling     1806 non-null   float64\n",
      " 20  sh_rolling     1806 non-null   float64\n",
      " 21  sot_rolling    1806 non-null   float64\n",
      " 22  dist_rolling   1806 non-null   float64\n",
      " 23  fk_rolling     1806 non-null   float64\n",
      " 24  pk_rolling     1806 non-null   float64\n",
      " 25  pkatt_rolling  1806 non-null   float64\n",
      " 26  home_code      1806 non-null   int64  \n",
      " 27  target_home    1806 non-null   int64  \n",
      "dtypes: float64(19), int64(9)\n",
      "memory usage: 395.2 KB\n"
     ]
    }
   ],
   "source": [
    "dataTrain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Training\n",
    "train_data = dataTrain.iloc[:, :-1].values\n",
    "train_labels = dataTrain.iloc[:, -1:].values\n",
    "\n",
    "# Data Testing\n",
    "test_data = dataTest.iloc[:, :-1].values\n",
    "test_labels = dataTest.iloc[:, -1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisasi Data\n",
    "scaler = MinMaxScaler()\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "\n",
    "# Pembentukan Data Sequence\n",
    "sequence_length = 27  # Panjang sequence yang akan digunakan\n",
    "num_features = train_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, labels, sequence_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - sequence_length + 1):\n",
    "        X.append(data[i:i+sequence_length])\n",
    "        y.append(labels[i+sequence_length-1])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_sequences(train_data, train_labels, sequence_length)\n",
    "X_test, y_test = create_sequences(test_data, test_labels, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pembangunan Model LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, input_shape=(sequence_length, num_features)))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 7s 124ms/step - loss: 0.6367 - accuracy: 0.6511\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 7s 121ms/step - loss: 0.5915 - accuracy: 0.6972\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 7s 127ms/step - loss: 0.5422 - accuracy: 0.7337\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 8s 138ms/step - loss: 0.4916 - accuracy: 0.7764\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 7s 127ms/step - loss: 0.4470 - accuracy: 0.8146\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 7s 127ms/step - loss: 0.4080 - accuracy: 0.8354\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 7s 127ms/step - loss: 0.3760 - accuracy: 0.8461\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 9s 165ms/step - loss: 0.3413 - accuracy: 0.8702\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 9s 156ms/step - loss: 0.3164 - accuracy: 0.8798\n",
      "Epoch 10/10\n",
      "55/56 [============================>.] - ETA: 0s - loss: 0.2953 - accuracy: 0.8943ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x000002AAF61AA0D0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"d:\\SMT 6 Project\\Data Analytics\\backend-api-da-project\\.venv\\Lib\\site-packages\\keras\\backend.py\", line 5159, in <genexpr>\n",
      "    output_ta_t = tuple(  File \"d:\\SMT 6 Project\\Data Analytics\\backend-api-da-project\\.venv\\Lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py\", line 243, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "56/56 [==============================] - 9s 164ms/step - loss: 0.2938 - accuracy: 0.8955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aafa9a7090>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pelatihan Model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)  # Sesuaikan dengan jumlah epoch dan ukuran batch yang optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 70ms/step - loss: 0.3032 - accuracy: 0.8748\n",
      "Loss: 0.3032\n",
      "Accuracy: 0.8748\n"
     ]
    }
   ],
   "source": [
    "# Testing Model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.2720 - accuracy: 0.9066\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.2540 - accuracy: 0.9129\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.2399 - accuracy: 0.9199\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.2303 - accuracy: 0.9192\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.2111 - accuracy: 0.9438\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 6s 130ms/step - loss: 0.2004 - accuracy: 0.9389\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 6s 144ms/step - loss: 0.1871 - accuracy: 0.9473\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 6s 139ms/step - loss: 0.1796 - accuracy: 0.9579\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 6s 137ms/step - loss: 0.1716 - accuracy: 0.9522\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 7s 147ms/step - loss: 0.1577 - accuracy: 0.9565\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.1702 - accuracy: 0.9494\n",
      "Epoch 1/10\n",
      "45/45 [==============================] - 6s 142ms/step - loss: 0.1578 - accuracy: 0.9544\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 5s 118ms/step - loss: 0.1497 - accuracy: 0.9593\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 5s 110ms/step - loss: 0.1380 - accuracy: 0.9691\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 5s 120ms/step - loss: 0.1294 - accuracy: 0.9740\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.1198 - accuracy: 0.9824\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 5s 109ms/step - loss: 0.1146 - accuracy: 0.9817\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 6s 132ms/step - loss: 0.1102 - accuracy: 0.9838\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 7s 151ms/step - loss: 0.1026 - accuracy: 0.9831\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 6s 136ms/step - loss: 0.0968 - accuracy: 0.9860\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 5s 117ms/step - loss: 0.0897 - accuracy: 0.9923\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.1011 - accuracy: 0.9775\n",
      "Epoch 1/10\n",
      "45/45 [==============================] - 5s 116ms/step - loss: 0.0889 - accuracy: 0.9930\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.0829 - accuracy: 0.9888\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.0791 - accuracy: 0.9909\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 5s 115ms/step - loss: 0.0727 - accuracy: 0.9937\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.0668 - accuracy: 0.9923\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.0638 - accuracy: 0.9944\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 5s 116ms/step - loss: 0.0613 - accuracy: 0.9958\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.0570 - accuracy: 0.9958\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 5s 112ms/step - loss: 0.0551 - accuracy: 0.9965\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 5s 115ms/step - loss: 0.0520 - accuracy: 0.9958\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.0806 - accuracy: 0.9747\n",
      "Epoch 1/10\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.0532 - accuracy: 0.9930\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.0556 - accuracy: 0.9958\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 5s 116ms/step - loss: 0.0495 - accuracy: 0.9958\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.0432 - accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 5s 115ms/step - loss: 0.0414 - accuracy: 0.9993\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.0381 - accuracy: 0.9993\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.0370 - accuracy: 0.9993\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.0351 - accuracy: 0.9993\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.0322 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 6s 134ms/step - loss: 0.0311 - accuracy: 1.0000\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.0689 - accuracy: 0.9747\n",
      "Epoch 1/10\n",
      "45/45 [==============================] - 6s 135ms/step - loss: 0.0440 - accuracy: 0.9930\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 5s 116ms/step - loss: 0.0346 - accuracy: 0.9986\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.0299 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 5s 115ms/step - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 5s 114ms/step - loss: 0.0220 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 5s 116ms/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 5s 113ms/step - loss: 0.0198 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 5s 115ms/step - loss: 0.0211 - accuracy: 1.0000\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.0274 - accuracy: 1.0000\n",
      "Fold 1: 0.9494\n",
      "Fold 2: 0.9775\n",
      "Fold 3: 0.9747\n",
      "Fold 4: 0.9747\n",
      "Fold 5: 1.0000\n",
      "Mean Accuracy: 0.9753\n",
      "Standard Deviation: 0.0160\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Tentukan jumlah lipatan (folds) untuk cross validation\n",
    "num_folds = 5\n",
    "\n",
    "# Buat objek KFold untuk melakukan cross validation\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# List untuk menyimpan skor akurasi pada setiap lipatan\n",
    "scores = []\n",
    "\n",
    "# Melakukan cross validation\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    # Bagi data menjadi data pelatihan dan data validasi pada lipatan saat ini\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    # Reset ulang model sebelum setiap pelatihan\n",
    "    model.reset_states()\n",
    "    \n",
    "    # Pelatihan Model pada lipatan saat ini\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=32)\n",
    "    \n",
    "    # Evaluasi model pada data validasi lipatan saat ini\n",
    "    _, accuracy = model.evaluate(X_val_fold, y_val_fold)\n",
    "    \n",
    "    # Menyimpan skor akurasi pada lipatan saat ini\n",
    "    scores.append(accuracy)\n",
    "\n",
    "# Tampilkan skor akurasi pada setiap lipatan\n",
    "for fold, score in enumerate(scores):\n",
    "    print(f\"Fold {fold+1}: {score:.4f}\")\n",
    "\n",
    "# Tampilkan rata-rata dan standar deviasi dari skor akurasi\n",
    "print(f\"Mean Accuracy: {np.mean(scores):.4f}\")\n",
    "print(f\"Standard Deviation: {np.std(scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1806 entries, 0 to 1805\n",
      "Data columns (total 28 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   round          1806 non-null   int64  \n",
      " 1   venue          1806 non-null   int64  \n",
      " 2   gf             1806 non-null   float64\n",
      " 3   ga             1806 non-null   float64\n",
      " 4   xg             1806 non-null   float64\n",
      " 5   xga            1806 non-null   float64\n",
      " 6   poss           1806 non-null   float64\n",
      " 7   formation      1806 non-null   int64  \n",
      " 8   sh             1806 non-null   float64\n",
      " 9   sot            1806 non-null   float64\n",
      " 10  dist           1806 non-null   float64\n",
      " 11  fk             1806 non-null   float64\n",
      " 12  pk             1806 non-null   float64\n",
      " 13  pkatt          1806 non-null   float64\n",
      " 14  venue_code     1806 non-null   int64  \n",
      " 15  opp_code       1806 non-null   int64  \n",
      " 16  hour           1806 non-null   int64  \n",
      " 17  day_code       1806 non-null   int64  \n",
      " 18  gf_rolling     1806 non-null   float64\n",
      " 19  ga_rolling     1806 non-null   float64\n",
      " 20  sh_rolling     1806 non-null   float64\n",
      " 21  sot_rolling    1806 non-null   float64\n",
      " 22  dist_rolling   1806 non-null   float64\n",
      " 23  fk_rolling     1806 non-null   float64\n",
      " 24  pk_rolling     1806 non-null   float64\n",
      " 25  pkatt_rolling  1806 non-null   float64\n",
      " 26  home_code      1806 non-null   int64  \n",
      " 27  target_home    1806 non-null   int64  \n",
      "dtypes: float64(19), int64(9)\n",
      "memory usage: 395.2 KB\n"
     ]
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [0, 0, 2, 0, 1, 1.2, 44, 15, 10, 2, 14.6, 1, 0, 0, 0, 6, 20, 4, 1.666666667, 2, 15, 5, 20.7, 0, 0.3333333333, 0.3333333333, 0]\n",
    "data_array = np.array(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = scaler.transform(data_array.reshape(1, -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = create_sequences(normalized_data, [], sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Melakukan prediksi pada data uji\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Melakukan invers normalisasi pada hasil prediksi\u001b[39;00m\n\u001b[0;32m      5\u001b[0m y_pred_inverse \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39minverse_transform(y_pred)\n",
      "File \u001b[1;32md:\\SMT 6 Project\\Data Analytics\\backend-api-da-project\\.venv\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\SMT 6 Project\\Data Analytics\\backend-api-da-project\\.venv\\Lib\\site-packages\\keras\\engine\\training.py:2407\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2403\u001b[0m                 callbacks\u001b[39m.\u001b[39mon_predict_batch_end(\n\u001b[0;32m   2404\u001b[0m                     end_step, {\u001b[39m\"\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m\"\u001b[39m: batch_outputs}\n\u001b[0;32m   2405\u001b[0m                 )\n\u001b[0;32m   2406\u001b[0m     \u001b[39mif\u001b[39;00m batch_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 2407\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2408\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnexpected result of `predict_function` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2409\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m(Empty batch_outputs). Please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2410\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2411\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2412\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39minformation of where went wrong, or file a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2413\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39missue/bug to `tf.keras`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2414\u001b[0m         )\n\u001b[0;32m   2415\u001b[0m     callbacks\u001b[39m.\u001b[39mon_predict_end()\n\u001b[0;32m   2416\u001b[0m all_outputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure_up_to(\n\u001b[0;32m   2417\u001b[0m     batch_outputs, potentially_ragged_concat, outputs\n\u001b[0;32m   2418\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `predict_function` (Empty batch_outputs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "# # Melakukan prediksi pada data uji\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Melakukan invers normalisasi pada hasil prediksi\n",
    "# y_pred_inverse = scaler.inverse_transform(y_pred)\n",
    "\n",
    "# # Menampilkan hasil prediksi\n",
    "# print(\"Hasil Prediksi:\")\n",
    "# for i in range(len(X_test)):\n",
    "#     print(f\"Data: {X_test[i]}, Prediksi: {y_pred_inverse[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
